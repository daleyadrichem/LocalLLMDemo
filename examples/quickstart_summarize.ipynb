{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9a18d23",
      "metadata": {},
      "source": [
        "# Quickstart: Summarize a document with a local LLM\n",
        "\n",
        "This notebook demonstrates how to use the `llm_local` library to summarize text using a\n",
        "locally running LLM (e.g. via Ollama).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd6a004",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running from the project root, make sure the package is importable.\n",
        "# If this fails, run: `pip install -e .` or `uv pip install -e .` from the project root.\n",
        "from llm_local import LocalLLM, LocalLLMConfig\n",
        "from llm_local.utils import load_text_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d69863",
      "metadata": {},
      "source": [
        "## Configure the local LLM\n",
        "\n",
        "We assume you have Ollama running (e.g. via `ollama serve`) and a model pulled\n",
        "(for example `ollama pull llama3.2:3b`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57dafef",
      "metadata": {},
      "outputs": [],
      "source": [
        "config = LocalLLMConfig(model=\"llama3.2:3b\")\n",
        "llm = LocalLLM(config=config)\n",
        "llm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccc5e09",
      "metadata": {},
      "source": [
        "## Load a document from disk\n",
        "\n",
        "For the workshop, you can point this at any `.txt` file (article, blog post, research paper, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5960d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change this path to an actual .txt file on your machine\n",
        "path_to_text = \"../example_document.txt\"  # update this path\n",
        "\n",
        "text = load_text_file(path_to_text)\n",
        "print(text[:1000])  # show first 1000 characters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f451590",
      "metadata": {},
      "source": [
        "## Summarize the document\n",
        "\n",
        "We use the high-level `summarize_text` method which will:\n",
        "\n",
        "1. Chunk the text (if it's long)\n",
        "2. Summarize each chunk\n",
        "3. Combine the summaries into an overall summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2906f756",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = llm.summarize_text(text, max_words=200, temperature=0.0)\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
